# Варианты инструментов

Держи этот список перед глазами, когда анализируешь новый сайт. Идем от легкого к тяжелому (сверху вниз).

---

### 1. "Чистый выстрел" (Direct API)

- **Стек:** `httpx` (Async) + `Pydantic`.
- **Для чего:** Идеальный сценарий. Ты нашел в Network вкладке запросы, возвращающие JSON.
- **Суть:** Ты игнорируешь HTML и фронтенд полностью. Твой скрипт притворяется фронтендом и общается напрямую с базой данных через API. Это дает максимальную скорость (тысячи запросов в секунду) и минимальный трафик, так как ты не качаешь мусор. Если есть возможность использовать этот метод — всегда выбирай его.

### 2. "Хирург" (Hydration Data / Hidden JSON)

- **Стек:** `httpx` + `json` (или `chompjs` для грязного JS) + `Selectolax`.
- **Для чего:** Сайты на Next.js, Nuxt.js или React, которые используют SSR. Данные в Network не летают, но страница грузится быстро.
- **Суть:** Разработчики вшивают "слепок" базы данных прямо в HTML-код страницы (обычно в теги `<script id="__NEXT_DATA__">` или переменную `window.__STATE__`). Вместо того чтобы парсить тысячи тегов `<div>`, ты просто находишь этот скрипт, вырезаешь текст и превращаешь его в чистый JSON. Это быстрее и надежнее классического парсинга, так как структура данных меняется реже, чем верстка.

### 3. "Классика" (Static HTML Parsing)

- **Стек:** `httpx` + `Selectolax` (для скорости) или `lxml` (для сложного XPath).
- **Для чего:** Старые сайты, блоги, форумы, SSR без гидратации. Данные лежат тупо в тексте внутри тегов `<div>`, `<span>`, `<table>`.
- **Суть:** Ты скачиваешь HTML как текст и скармливаешь его парсеру, который строит DOM-дерево. Дальше ты пишешь CSS-селекторы или XPath, чтобы найти нужные куски текста. Метод надежный, но ломается, если дизайнер решит переименовать классы или изменить верстку. Требует постоянной поддержки.

### 4. "Хамелеон" (TLS Impersonation)

- **Стек:** `curl_cffi` или `tls_client`.
- **Для чего:** Защищенные API, которые отдают `403 Forbidden` обычным библиотекам, но работают в браузере. (Cloudflare, Akamai).
- **Суть:** Проблема не в заголовках, а в "почерке" шифрования (TLS Fingerprint). Обычный Python палится сразу. Эти библиотеки подменяют низкоуровневые параметры рукопожатия (Handshake), полностью имитируя поведение реального Chrome или Safari. Сервер думает, что ты браузер, и отдает данные без запуска тяжелого Selenium.

### 5. "Танк" (Headless Browser Automation)

- **Стек:** `Playwright` (Python version).
- **Для чего:** Сложные SPA (Single Page Applications), где логика размазана по сотне JS-файлов, API нет или оно зашифровано, а контент появляется только после кликов и скролла.
- **Суть:** Ты запускаешь реальный браузер (Chromium) без графического интерфейса. Скрипт управляет им: нажимает кнопки, ждет появления элементов, скроллит. Это медленно и жрет много памяти (RAM), но гарантированно работает, так как сайт видит полноценный движок рендеринга. Используй только если предыдущие методы не сработали.

### 6. "Спецназ" (Stealth / Anti-Bot Bypass)

- **Стек:** `DrissionPage`.
- **Для чего:** Сайты с агрессивной защитой, капчами (Turnstile, ReCaptcha) и детекторами ботов, которые банят даже Playwright.
- **Суть:** Инструмент управляет браузером напрямую через протокол CDP, минуя стандартные драйверы (WebDriver), которые легко детектятся. Он умеет имитировать движения мыши, проходить простые проверки "Я не робот" и переключаться между режимом браузера и режимом запросов на лету. Это "тяжелая артиллерия" для самых сложных целей.

### 7. "Радист" (WebSockets)

- **Стек:** `websockets` или `aiohttp` (ws mode).
- **Для чего:** Живые данные в реальном времени: биржевые котировки, ставки на спорт, чаты, аукционы.
- **Суть:** Вместо того чтобы долбить сервер запросами ("цена изменилась?"), ты открываешь одно постоянное соединение. Сервер сам присылает тебе обновления (Push-уведомления) в формате JSON, как только что-то происходит. Это самый эффективный способ сбора динамических данных, но требует написания бесконечного цикла прослушивания (`while True`).

### 8. "Черный ход" (Mobile App API / MITM)

- **Стек:** `mitmproxy` / `Charles Proxy` (для перехвата) -> `httpx` (для повтора запросов).
- **Для чего:** Когда веб-сайт защищен как Пентагон (Cloudflare, Captcha на каждом клике), а у компании есть **Мобильное приложение**.
- **Суть:** Защиту на веб ставят часто, а про API для мобилок забывают или ленятся. Ты берешь эмулятор Android, ставишь сертификат `mitmproxy`, запускаешь их приложение и смотришь, куда оно стучится. Часто там летает чистейший JSON вообще без защиты или с примитивным токеном. Это "Золотая жила", про которую забывают новички, долбясь в закрытую веб-дверь.